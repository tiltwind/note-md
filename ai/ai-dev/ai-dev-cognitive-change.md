<!--
markmeta_author: tiltwind
markmeta_date: 2026-02-27
markmeta_title: 人在AI开发中的角色演进
markmeta_categories: ai
markmeta_tags: ai,ai-dev,cognitive-change
-->

# 人在AI开发中的角色演进

随着大语言模型能力的飞速进化，我对 AI 开发的认知也经历了深刻的变化。
从最初把 AI 当作一个"智能补全器"，到如今可以将完整需求交给 AI Agent 自主完成，每一次跃迁都伴随着开发模式的重构和工程师角色的重新定义。

本文以 **人的角色演进** 为主轴，梳理这一变化历程。
每一次阶段跃迁的本质，是人"放下"了某项具体工作，将其交给 AI，同时承担起更高层次的职责。

```
编码者 → 审查者 → 指挥者 → 验收者 → Tech Lead
  放下键盘   放下红笔   放下操控杆   放下单任务
```


## 1. 编码者：人写代码，AI 加速打字

> 2021 – 2023，以 GitHub Copilot 为代表

### 1.1 AI 能力

- 基于上下文的行级/块级代码补全
- 根据注释生成简单函数体
- 模式匹配：识别重复代码模式并自动续写
- 能力边界明确：只能在光标处做局部预测，无法理解跨文件关系

### 1.2 开发模式

工程师在 IDE 中编写代码，AI 在光标处实时提供补全建议，工程师按 Tab 接受或忽略。本质上是 **"人写代码，AI 加速敲键盘"**。

```
工程师编写代码 → AI 实时补全建议 → 工程师接受/忽略 → 继续编写
```

### 1.3 工程师核心关注点

- **编写代码本身**：逻辑设计、架构决策、代码质量全部由人负责
- **判断补全质量**：快速判断 AI 建议是否正确
- **保持编码节奏**：AI 是加速器，不是决策者

### 1.4 典型范例

```python
# 工程师输入注释
# 计算两个日期之间的工作日天数

# AI 自动补全函数体
def count_workdays(start_date, end_date):
    count = 0
    current = start_date
    while current <= end_date:
        if current.weekday() < 5:  # Monday = 0, Friday = 4
            count += 1
        current += timedelta(days=1)
    return count
```

工程师写注释或函数签名，AI 补全实现。工程师需要逐行审查补全内容是否正确。

### 1.5 典型挑战

- 补全质量不稳定，接受错误补全反而引入 Bug
- 过度依赖补全可能导致基础编码能力退化
- AI 只见过公开代码，对私有业务逻辑无能为力

### 1.6 认知

- AI 是一个 **效率工具**，和 IDE 的 snippet、模板生成没有本质区别
- AI 不理解业务，只是"见过类似的代码"
- 核心价值：减少重复劳动，加快编码速度
- 工程师的技能壁垒不受影响

> **跃迁驱动力**：随着 LLM 能力增强，工程师发现 AI 不仅能补全一行，还能生成整个函数甚至文件。手动逐行编写开始显得低效——为什么不让 AI 直接写，我来审查？


## 2. 审查者：AI 写代码，人逐行审查

> 2023 – 2024，以 ChatGPT/Claude 对话式编程、Cursor Chat 为代表

### 2.1 AI 能力

- 理解自然语言需求描述，生成完整的代码文件
- 能修改现有代码，进行重构和 Bug 修复
- 支持多轮对话，逐步细化需求
- 开始具备跨文件理解能力，但上下文窗口有限

### 2.2 开发模式

工程师用自然语言描述需求，AI 生成或修改代码，工程师逐行 Review 并手动应用修改。核心是 **"人描述需求，AI 写代码，人审查每一行"**。

```
工程师描述需求 → AI 生成/修改代码 → 工程师逐行 Review → 手动应用修改 → 反馈调整 → 循环
```

> **关于 Vibe Coding**：Andrej Karpathy 于 2025 年提出 Vibe Coding 概念——"完全放弃理解代码，拥抱直觉"。这实际上是审查者阶段的 **反模式**：放弃了 Review 职责的审查者。Simon Willison 进一步区分了 Vibe Coding（不审查、凭感觉）和 Vibe Engineering（利用 AI 但结合测试、Review 等工程实践）。本阶段的正确做法是后者。

### 2.3 工程师核心关注点

- **Review 每一行代码**：AI 会产生幻觉，生成看似正确但实际有问题的代码
- **指导 AI 修改方向**：通过多轮对话引导 AI 逼近期望结果
- **维护代码一致性**：AI 生成的代码风格、命名、架构可能和项目不一致
- **管理上下文**：对话过长后 AI 会"忘记"前面的约定

### 2.4 典型范例

```
工程师：帮我写一个用户注册的 API，使用 Go + Gin 框架，需要验证邮箱格式和密码强度。

AI：[生成 200 行代码]

工程师：（Review 后发现）密码校验逻辑不对，应该要求至少包含大小写字母和数字，
       而且错误返回格式不符合我们项目的统一响应格式，请参考 xxx.go 的写法。

AI：[修改后重新生成]

工程师：（继续 Review）这次密码校验对了，但你把邮箱验证的正则改错了...
```

每一轮生成都需要工程师仔细审查，往往需要 3-5 轮对话才能得到满意的结果。

### 2.5 典型挑战

- **Review 疲劳**：逐行审查 AI 输出的认知负荷极高，METR 研究（2025）发现这实际可能增加 19% 的时间开销
- **幻觉代码**：AI 生成的代码"看起来对"但逻辑有隐蔽错误，比人手写的 Bug 更难发现
- **上下文丢失**：长对话后 AI 会遗忘早期约定，导致反复纠正
- **生产力悖论**：开发者主观感觉效率提升，但客观度量可能并未提升

### 2.6 认知

- AI 是一个 **能力很强但不可靠的结对程序员**，必须时刻监督
- 生成代码不等于正确代码，**Review 成本很高**
- AI 适合处理 "已知模式" 的代码，创新性工作仍需人主导
- 开始意识到：给 AI 的需求越清晰，产出质量越高
- 工程师的核心技能从"写代码"开始向"审代码 + 描述需求"迁移

> **跃迁驱动力**：逐行 Review 的疲劳感和低效率成为核心痛点。工程师开始思考：能不能让 AI 先出方案，我审方案而不是审代码？能不能让 AI 像一个可指挥的 Agent，而不是一个需要逐字检查的打字员？


## 3. 指挥者：人审核方案，实时操控 Agent

> 2024 – 2025，以 Cursor Agent、Claude Code、Windsurf 等 IDE Agent 为代表

### 3.1 AI 能力

- 从对话式问答升级为 **Agent 模式**：AI 能自主执行多步操作（读文件、改代码、运行命令）
- 支持 Plan 模式：先输出执行计划，确认后再执行
- 具备较强的项目上下文理解能力（通过 CLAUDE.md、.cursorrules 等机制）
- 能在多个文件之间协调修改，保持一致性
- 支持结构化工作流：Spec → Plan → Task → Code

### 3.2 开发模式

工程师像指挥者（Conductor）一样与 Agent 紧密协作：定义需求或 Spec，审核 Agent 的执行计划，在关键节点给予指令调整。**"人审方案、指挥行动，AI 执行落地"**。

```
工程师定义需求/Spec → AI 生成 Plan → 工程师审核 Plan → AI 执行（读写文件、运行命令）→ 工程师在关键节点调整方向 → 微调交付
```

信任度在这个阶段呈渐进式增长：
- **权限模式**：Agent 每步操作都需要人确认（早期）
- **半自主模式**：只在关键操作时确认（中期）
- **YOLO 模式**：完全信任 Agent 自主执行（后期）

### 3.3 工程师核心关注点

- **审核 Plan 的正确性**：确保 AI 理解了真正的需求，方案合理
- **提供完整的背景知识**：通过 CLAUDE.md、项目规范等让 AI 做出正确决策
- **实时方向调整**：在 Agent 执行过程中观察并纠偏
- **需求拆分**：将大需求拆分为 Agent 能可靠完成的模块级任务
- **轻量级代码 Review**：不再逐行审查，重点看架构决策和边界情况

### 3.4 典型范例

```
工程师：请根据 user-api.yml OpenAPI 定义，开发用户管理页面 static/views/system/user，
       包括搜索、列表展示、详情、新增、编辑、删除功能。
       详情、新增、编辑、删除分别点击按钮弹框进行操作。

AI Agent：[进入 Plan 模式，输出执行计划]
    1. 分析 user-api.yml 中的接口定义...
    2. 创建 User.html 模板，包含搜索栏和表格...
    3. 创建 User.js，实现数据加载、分页、CRUD 操作...
    4. 创建 User.css，样式与项目风格保持一致...

工程师：（审核 Plan）Plan 没问题，执行吧。
       另外搜索要支持按角色筛选，Plan 里漏了。

AI Agent：[更新 Plan 并执行，自主完成文件创建和代码编写]
```

工程师的重心从"逐行 Review 代码"转移到"审核计划是否符合需求"，效率大幅提升。

### 3.5 典型挑战

- **上下文管理负担**：Agent 的表现高度依赖提供的上下文质量，维护 CLAUDE.md 等规范本身是额外工作
- **Plan 与执行的偏差**：AI 的 Plan 看起来合理，但执行时可能偏离
- **信任度校准困难**：过度信任导致问题遗漏，信任不足则退化回审查者模式
- **放大效应**：DORA 2025 研究发现，AI 不会修复已有问题，反而放大团队现有的优势或短板

### 3.6 认知

- AI 已经是一个 **可指挥的 Agent**，能自主执行多步操作
- **需求质量决定产出质量**：给 AI 足够清晰的背景和需求，它能交付高质量代码
- 工程师的核心价值从"写代码"转向 **"定义需求 + 架构决策 + 方案审核"**
- 代码 Review 从 "逐行审查" 变为 "抽查 + 运行验证"
- 开始思考：能否让 AI 自己验证自己，从而不需要人实时操控？

> **跃迁驱动力**：实时操控 Agent 仍然是"一人一 Agent"的串行模式，人是瓶颈。工程师开始思考：能否前置定义好约束和验收标准，让 Agent 自驱完成并自我验证，从而解放人的实时关注？


## 4. 验收者：人定义约束，只看结果

> 2025 – 2026，以 TDD 驱动、自动化测试约束、CI 质量门禁为代表

### 4.1 AI 能力

- TDD 驱动：AI 先根据需求生成测试用例，再编写实现代码，形成"红-绿-重构"闭环
- 自我纠错：运行测试失败后能分析原因并自动修复，直到全部通过
- 端到端验证：AI 能自主运行单元测试、集成测试、E2E 测试，确保功能正确
- 支持 Hook、CI 集成，代码提交前自动通过 lint、静态分析、测试等质量门禁
- 人可以同时管理多个 Agent 任务，因为不需要实时关注每个 Agent 的过程

### 4.2 开发模式

工程师的工作被 **前置** 和 **后置** 两段化：前置定义需求、验收标准和约束规则，后置检查测试是否通过、功能是否符合预期。中间过程由 Agent 自驱完成。**"人定义约束，AI 在约束内自主交付，人只验收结果"**。

```
工程师定义需求 + 验收标准 + 约束规则 → [人退出过程] → AI 生成测试 → AI 编写实现 → 自动运行测试 → 失败则自动修复 → 全部通过 → 人验收结果
```

对应 Addy Osmani 的 **Orchestrator** 角色：前端装载（写 Spec、设约束）、后端验收（看测试结果）、中间不介入。一个 Orchestrator 可以并行管理的总工作量远超实时操控单个 Agent 的模式。

### 4.3 工程师核心关注点

- **定义清晰的需求和验收标准**：这是驱动一切的源头
- **设计验证约束**：定义测试策略、质量门禁、架构约束规则
- **维护约束基础设施**：测试框架、CI/CD Pipeline、lint 规则、开发规范
- **验收最终产出**：不看代码细节，只看测试是否通过、功能是否符合预期
- **并行管理多个任务**：同时发出多个需求，分别验收

### 4.4 典型范例

```
工程师：实现订单超时自动取消功能。

       验收标准：
       1. 订单创建 30 分钟后未支付，自动标记为"已取消"
       2. 取消时释放库存
       3. 发送取消通知给用户
       4. 并发场景下不会重复取消

       约束：
       - 使用延迟队列实现
       - 编写单元测试覆盖所有边界情况
       - 编写集成测试验证完整流程
       - 所有测试通过后提交

AI Agent：
  [步骤1: 分析需求，生成测试用例 - 15个单元测试 + 3个集成测试]
  [步骤2: 运行测试 → 全部失败（红）]
  [步骤3: 编写实现代码]
  [步骤4: 运行测试 → 2个失败 → 分析原因 → 修复 → 全部通过（绿）]
  [步骤5: 运行 lint + 静态分析 → 通过]
  [完成: 所有验收标准已通过验证]
```

工程师无需查看代码，测试和质量门禁就是"自动化审查员"。

### 4.5 典型挑战

- **约束设计能力要求高**：验收标准写得不好，AI 交付的就是"通过了但不对"的代码
- **测试本身的质量**：AI 生成的测试可能覆盖不全或断言过于宽松
- **难以约束的维度**：性能、安全性、可维护性等难以用自动化测试完全覆盖
- **过度信任自动化**：测试全绿不等于没有问题，边界情况可能恰好是测试未覆盖的

### 4.6 认知

- AI 是一个 **可自驱的开发者**，测试就是它的"监督者"
- **代码正确性由测试保证**，而非人工 Review
- 工程师的核心价值转向 **"需求定义 + 约束设计 + 结果验收"**
- 软件质量的保障方式从 "人工 Review" 转向 **"自动化验证"**
- 核心认知：**好的约束 > 好的代码**，约束体系的质量决定了产出质量

> **跃迁驱动力**：单 Agent 的"自己写自己审"仍然有局限——谁来验证约束本身是否完备？系统级的复杂变更超出单 Agent 能力范围。工程师开始需要多个 Agent 分工协作、互相制衡。


## 5. Tech Lead：人管理 AI 工程团队

> 2026+，以多 Agent 协作、角色分工、项目级自主交付为代表

### 5.1 AI 能力

- 多 Agent 协作：不同角色的 Agent（架构师、开发者、测试员、审查员）组成团队
- Agent 编排与调度：Orchestrator Agent 负责任务分解、分配和协调
- 跨模块协作：多个 Agent 并行处理不同模块，自动处理模块间依赖和接口对齐
- Agent 间互审：Code Agent 写的代码由 Review Agent 审查，Test Agent 独立编写测试
- 项目级理解：Agent Team 能维护项目全局上下文，处理跨系统、跨服务的复杂变更

### 5.2 开发模式

工程师像 Tech Lead 一样给出项目级需求，Agent Team 自主完成从架构设计到代码交付的全过程。
各角色 Agent 分工协作、互相验证，形成内部的 Review 和制衡机制。**"人是 Tech Lead，AI 是工程团队"**。

```
工程师给出项目需求 → Orchestrator Agent 分解任务
  → Architect Agent 设计架构
  → Dev Agent(s) 并行编码
  → Test Agent 独立编写测试并验证
  → Review Agent 审查代码质量
  → 发现问题则反馈给 Dev Agent 修复
  → 全部通过 → 交付
```

### 5.3 工程师核心关注点

- **定义项目目标和业务需求**：从功能级上升到项目级
- **架构决策与技术选型**：重大架构决策仍需人拍板
- **审核 Agent Team 的分工和方案**：确认任务分解和架构设计合理
- **验收最终交付物**：关注系统整体行为，而非单个模块

### 5.4 典型范例

```
工程师：我们需要为系统增加多租户支持。要求：
       1. 数据层面完全隔离，每个租户独立 schema
       2. API 层通过 header 识别租户
       3. 现有功能全部兼容，不影响已有租户
       4. 需要租户管理后台（CRUD + 配额管理）

Agent Team：
  [Orchestrator: 分解为 4 个子任务，分配给不同 Agent]
  [Architect Agent: 设计多租户架构方案，输出架构文档]
  [Dev Agent 1: 改造数据层，实现 schema 隔离和动态路由]
  [Dev Agent 2: 改造 API 中间件，实现租户识别和注入]
  [Dev Agent 3: 开发租户管理后台页面和 API]
  [Test Agent: 为每个模块独立编写测试，编写跨模块集成测试]
  [Review Agent: 审查各模块代码，检查接口一致性和安全性]
  [Dev Agent 1: 根据 Review 反馈修复数据层隔离漏洞]
  [集成验证: 全部模块联调测试通过]
  [完成: 输出变更摘要和部署指南]
```

工程师只需在关键节点（架构方案确认、最终验收）介入，中间过程由 Agent Team 自主运转。

### 5.5 典型挑战

- **协调成本**：多 Agent 之间的信息同步和冲突解决是新的工程问题
- **一致性保障**：不同 Agent 对同一概念的理解可能产生偏差
- **可观测性**：Agent Team 的决策过程需要对人透明，否则出了问题难以溯源
- **当前成熟度**：多 Agent 编排仍处于早期实验阶段（如 Claude Agent SDK、OpenAI Swarm），距离可靠的生产级使用仍有距离

### 5.6 认知

- AI 不再是单兵作战，而是一个 **可协作的工程团队**
- **分工和制衡机制** 解决了单 Agent 的"自己写自己审"问题
- 工程师的角色从"约束设计者"上升为 **"Tech Lead / 产品负责人"**
- 软件工程的瓶颈从"编码产能"转向 **"需求定义和架构决策"**
- 核心认知：**管理 AI 团队和管理人类团队一样，需要清晰的目标、合理的分工和有效的制衡**


## 6. 阶段对比总结

| 维度 | 编码者 | 审查者 | 指挥者 | 验收者 | Tech Lead |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **时间** | 2021-2023 | 2023-2024 | 2024-2025 | 2025-2026 | 2026+ |
| **代表工具** | Copilot | ChatGPT, Cursor Chat | Cursor Agent, Claude Code | Claude Code + TDD + CI | Multi-Agent 编排框架 |
| **AI 角色** | 打字助手 | 结对程序员 | 可指挥的 Agent | 自驱开发者 | 工程团队 |
| **人做什么** | 写代码 | Review 每行代码 | 审核 Plan、实时指挥 | 定义约束、验收结果 | 定义目标、架构决策 |
| **人不再做什么** | — | 不再亲手写 | 不再逐行 Review | 不再实时操控 | 不再管单个任务 |
| **交互粒度** | 行/块 | 文件 | 模块/功能 | 需求/验收标准 | 项目/系统 |
| **信任度** | 不信任 | 低信任（逐行验证） | 中信任（Plan 级验证） | 高信任（结果级验证） | 委托信任 |
| **质量保障** | 人工编写 | 人工逐行 Review | 审核 Plan + 抽查代码 | 自动化测试驱动 | Agent 互审 + 自动化 |
| **典型挑战** | 补全质量不稳定 | Review 疲劳 | 上下文管理、信任校准 | 约束设计能力要求高 | 协调成本、一致性 |
| **角色跃迁** | — | 放下键盘 | 放下红笔 | 放下操控杆 | 放下单任务 |


## 7. 对未来的展望

### 7.1 下一阶段：意图编程（Intent Programming）

随着 AI 能力继续增强，下一个阶段可能进入 **意图编程** 时代：

- **工程师只需表达业务意图**，不再需要拆分需求、定义验收标准、设计约束
- AI 能自主理解业务上下文，自动推导验收标准和约束条件
- AI 具备 Online Learning 能力，能从团队的反馈中持续学习和进化
- 工程师的角色进一步转变为 **"产品思维者"** — 思考 What 和 Why，所有 How 交给 AI

```
工程师："我们的用户流失率在注册后第3天达到峰值，需要改善新用户引导体验。"

AI：[自主分析用户行为数据 → 设计引导方案 → 实现功能 → A/B测试 → 输出结果报告]
```

### 7.2 当前的现实约束

通往意图编程的路上仍有显著障碍：

- **可靠性**：AI 的输出仍不稳定，2025 年行业焦点正从"追求速度"转向"追求质量"
- **安全性**：约 45% 的 AI 生成代码存在安全隐患，自动化安全审计尚不成熟
- **可观测性**：AI 的决策过程仍是黑箱，出了问题难以溯源和复现
- **标准化**：MCP（Model Context Protocol）等协议正在推动工具与 Agent 的标准化通信，但生态仍在早期
- **组织适配**：DORA 2025 的核心发现是 AI 放大团队现状——流程混乱的团队引入 AI 只会更混乱

### 7.3 终局：AI 原生软件工程

终局不是 AI 替代程序员，而是 **软件工程的范式彻底改变**：

- **代码成为中间编译产物**：就像今天没人关心编译器生成的机器码，未来也不会有人关心 AI 生成的代码
- **需求即程序**：自然语言描述的需求直接等价于可执行的软件，中间不再需要"编码"这个环节
- **持续自适应**：软件能根据运行时数据和用户反馈自动演化，不再需要人工迭代
- **验证变成唯一工程活动**：人唯一要做的是定义"什么是正确的"，而非"如何做到正确"

### 7.4 带来的影响

**对个人**：
- 编程技能的价值从"编码能力"迁移到"问题定义能力"和"系统思维"
- 软件工程师的门槛不再是"会写代码"，而是"能精确定义需求和约束"
- 学习路径改变：理解业务、定义问题、设计验证策略 > 学习语法和框架

**对团队**：
- 团队规模可能大幅缩减，少数人 + AI Agent 即可完成过去需要大团队的工作
- 协作方式从"分工写代码"变为"协作定义需求和约束"
- Code Review 将逐步被 Spec Review 和验收测试取代

**对行业**：
- 软件开发成本大幅降低，更多创意能变为现实
- "程序员"这个职业会演化，核心竞争力从技术实现转向领域理解和问题建模
- 软件的创造门槛降低，但高质量软件的设计门槛不会降低 — 理解用户、定义正确的问题始终是最难的事


## 参考

- Andrej Karpathy, "Vibe Coding" — https://x.com/karpathy/status/1886192184808149383
- Simon Willison, "Not all AI-assisted programming is vibe coding" — https://simonwillison.net/2025/Mar/19/vibe-coding/
- GitHub Blog, Spec-Driven Development — https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with-a-new-open-source-toolkit/
- Anthropic, Claude Code Best Practices — https://docs.anthropic.com/en/docs/claude-code/best-practices
- Steve Yegge, Developer-Agent Evolution Model — https://steve-yegge.medium.com/the-future-of-coding-agents-e9451a84207c
- Addy Osmani, "Conductors to Orchestrators" — https://addyosmani.com/blog/future-agentic-coding/
- DORA 2025 State of AI-Assisted Software Development — https://dora.dev/research/2025/dora-report/
- METR, AI Experienced OS Developer Productivity Study — https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/
- Nicholas Zakas, "From Coder to Orchestrator" — https://humanwhocodes.com/blog/2026/01/coder-orchestrator-future-software-engineering/
- GitHub Octoverse 2025, The New Identity of a Developer — https://github.blog/news-insights/octoverse/the-new-identity-of-a-developer-what-changes-and-what-doesnt-in-the-ai-era/
