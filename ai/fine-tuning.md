<!---
markmeta_author: titlwind
markmeta_date: 2025-02-19
markmeta_title: 模型微调(fine-tuning)
markmeta_categories: ai
markmeta_tags: ai,fine-tuning
-->


# 微调

> 注意: 部分内容来自AI生成，可能存在错误，如有发现，欢迎指正！


## 1. 什么是微调


### 1.1. 预训练 vs 微调

- **大模型训练（Pre-training）**  
  - **目标**：通过海量通用数据（如网页、书籍）学习语言的底层模式和知识（语法、逻辑、常识）。  
  - **方法**：无监督或自监督学习（如预测被遮挡的词、生成下一句话）。  
  - **特点**：需要巨量计算资源（数千张GPU/TPU）、长时间训练（数周至数月）。  
  - **输出**：通用基础模型（如GPT-3、BERT）。

- **微调（Fine-tuning）**  
  - **目标**：在预训练模型基础上，用特定领域数据（如医学文献、法律合同）适配具体任务（分类、问答）。  
  - **方法**：监督学习（使用标注数据调整模型参数）。  
  - **特点**：资源消耗低（单卡或少量GPU）、训练时间短（几小时至几天）。  
  - **输出**：领域专用模型（如医疗问答机器人）。

| **维度**| **大模型训练**  | **微调** |
|----------------|----------------------------|-----------------------------|
| **数据**| 通用数据（TB级） | 领域数据（GB级） |
| **任务**| 学习语言基础能力 | 适配具体任务（如分类、生成） |
| **参数更新**| 所有参数从头训练 | 部分或全部参数小幅调整  |
| **资源需求**| 千亿级算力（如超算集群）| 百亿级算力（如单台服务器） |
| **典型模型**| GPT-4、LLAMA、PaLM| ChatGPT（基于GPT-3微调）|


## 2. 什么时候需要微调

### 2.2. 微调的好处

- **微调可以做 RAG 能做的所有事情，但 RAG 不能**：  Fine-tuning 可以通过在训练期间将外部知识直接嵌入到模型中来复制 RAG 的功能，使其能够在不依赖外部系统的情况下执行诸如回答小众问题或总结文档等任务。微调还可以将上下文和模式集成到模型中，模拟检索行为。
- **特定任务更强的掌控能力**：微调将有关领域或任务知识直接嵌入到模型中，使其能够高精度地处理结构化、重复或细微差别的查询，这是 RAG 无法单独实现的。
- **独立于检索**： 微调模型无需外部数据即可有效运行，即使在检索系统出现故障或知识库不完整时也能确保无缝性能。
- **更快的推理**： 微调模型无需检索步骤即可提供直接响应，使其成为速度至关重要的场景的理想选择。
- **自定义行为和语气**： 微调允许精确控制模型的行为和通信方式，确保与品牌声音、法规要求或其他约束保持一致。
- **系统降级稳健性**： 在组合系统中，微调模型可确保可靠任务性能的基线水平，即使 RAG 系统检索不相关或不完整的信息也是如此。


### 2.3. 为什么你应该结合RAG和微调呢？

- **任务处理更专业**：微调擅长于特定任务，而 RAG 则动态检索最新或外部知识。它们共同处理核心和特定于上下文的需求。
- **适应性**：RAG 使系统无需不断重新训练即可保持最新状态。
- **效率**：微调建立了基线，而 RAG 通过处理动态细节减少了对详尽训练的需求。



## 3. 微调相关概念


### 3.1. LoRA

LoRA模型，全称Low-Rank Adaptation of Large Language Models，是一种用于微调大型语言模型的低秩适应技术。它最初应用于NLP领域，特别是用于微调GPT-3等模型。LoRA通过仅训练低秩矩阵，然后将这些参数注入到原始模型中，从而实现对模型的微调。这种方法不仅减少了计算需求，而且使得训练资源比直接训练原始模型要小得多，因此非常适合在资源有限的环境中使用。

在Stable Diffusion（SD）模型的应用中，LoRA被用作一种插件，允许用户在不修改SD模型的情况下，利用少量数据训练出具有特定画风、IP或人物特征的模型。这种技术在社区使用和个人开发者中非常受欢迎。例如，可以通过LoRA模型改变SD模型的生成风格，或者为SD模型添加新的人物/IP。

LoRA模型的使用涉及安装插件和配置参数。用户需要下载适合的LoRA模型和相应的checkpoint模型，并将其安装到相应的目录。在使用时，可以将LoRA模型与大模型结合使用，通过调整LoRA的权重来控制生成图片的结果。LoRA模型的优点包括训练速度快、计算需求低、训练权重小，因为原始模型被冻结，我们注入新的可训练层，可以将新层的权重保存为一个约3MB大小的文件，比UNet模型的原始大小小了近一千倍。

总的来说，LoRA模型是一种高效、灵活且适用于多种场景的模型微调技术，它在保持原始模型性能的同时，允许用户根据需要进行定制化调整。

> 参考: LoRA: Low-Rank Adaptation of Large Language Models, https://arxiv.org/abs/2106.09685


### 3.2. QLoRA

QLoRA是一种针对大语言模型的高效微调方法，能在有限的显存条件下，如48GB GPU上微调65B参数模型，同时保持与16位精度相当的性能。

通过**4位浮点数量化、双量化和分页优化器**，QLoRA解决了显存瓶颈问题，实现了在消费级硬件上微调大型模型。但会存在精度丢失问题, Unsloth 的动态 4 位量化在很大程度上减少了精度丢失问题。

此外，QLoRA微调的模型在聊天机器人任务中展现出与ChatGPT相当的性能，降低了计算资源的门槛。

> 参考: QLoRA: Efficient Finetuning of Quantized LLMs, https://arxiv.org/abs/2305.14314



## 4. 模型的选择



| **模型类型** | **定义**  | **应用场景**  | **核心特点**  | **范例**  | **是否适合微调** | **原因**  |
|-------------|----------|--------------|--------------|----------|-----------------|----------|
| **基座模型** | 大规模预训练模型，具备通用能力，可适配多种下游任务  | 文本生成、翻译、问答、代码生成等通用场景| 参数规模大（亿至千亿级）、训练成本高、泛化能力强  | GPT-4、Gemma、Llama 2  | 是 | 通过微调可快速适应垂直领域，预训练阶段已学习通用知识 |
| **推理模型** | 专为多步骤逻辑推理设计，需生成中间思考过程或验证步骤| 数学证明、代码调试、复杂逻辑问题 | 强调链式思考（CoT）、依赖高质量推理数据、计算成本高| DeepSeek-R1、OpenAI o1  | 有限| 需结合SFT+RL优化，简单微调易导致“幻觉”或推理能力退化 |
| **多模态模型** | 融合文本、图像、语音等多种模态数据的端到端模型 | 跨模态生成（文生图/视频）、多模态理解（图像问答）、语音交互| 模态对齐技术复杂、训练数据多样、算力需求极高| Step-1o、GPT-4V  | 部分| 需多模态对齐微调，但部分模态（如视觉）微调成本极高|
| **蒸馏模型** | 通过知识蒸馏将大模型能力迁移到小模型，降低部署成本| 移动端/边缘设备部署、实时性要求高的场景 | 参数规模小（亿级以下）、推理速度快、性能接近原模型| CodeGemma 2B、TinyLlama  | 否 | 蒸馏后模型压缩了知识表示，微调空间有限 |
| **视觉大模型** | 专注图像处理任务的预训练模型，如分类、检测、生成  | 图像编辑、遥感解译、医学影像分析 | 依赖卷积或视觉Transformer架构、需大规模标注数据  | DALL-E 3、Step-Video V2  | 是 | 可通过迁移学习适应细分场景（如特定医学影像分类）  |
| **垂直模型** | 针对特定领域（如医疗、法律、不动产）深度优化的模型，可能从头训练  | 行业知识问答、专业文档分析、业务流程自动化 | 领域数据占比高、参数规模适中、输出需符合行业规范  | 不动产登记大模型、法律合同解析模型  | 是 | 需注入领域知识库和业务规则，微调可提升准确性与合规性 |
| **行业大模型** | 基于基座模型注入行业数据训练，兼顾通用能力与行业特性  | 金融风控、供应链预测、能源调度| 通用数据与行业数据混合训练、支持行业术语和业务流程| 自然资源大模型、华为矿山大模型  | 是 | 行业数据分布差异大，需微调平衡通用性与专业性  |
| **代码生成模型** | 专为代码理解与生成设计的垂类模型，支持多种编程语言  | 代码补全、漏洞检测、自动化测试| 语法树嵌入、代码上下文建模、需高质量代码库训练 | CodeGemma 7B、CodeLlama  | 是 | 可通过领域代码库（如Web3合约）微调提升特定语言/框架支持  |

**补充说明**  
- **微调适配性**：基座模型和行业模型最适合微调，因其设计目标即为下游任务适配；推理模型和蒸馏模型微调需谨慎，易破坏原有能力。  
- **趋势融合**：当前模型边界逐渐模糊（如多模态模型兼具生成与推理），实际应用中常采用混合架构（如Step-1o融合文本/语音/视觉+推理能力）。  
- **成本权衡**：大模型微调依赖计算资源（如LoRA需8xA100），垂直领域可优先选择行业大模型而非从基座开始训练。



## 5. 微调数据格式

参考： https://www.xfyun.cn/doc/spark/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E.html



## 6. 开放数据集

- Registry of Open Data on AWS, https://registry.opendata.aws/
- AI Studio数据集, https://aistudio.baidu.com/aistudio/datasetoverview, 百度AI Studio的人工智能学习与实训社区，提供开放数据集。
- 天池数据集, https://tianchi.aliyun.com, 阿里对外开放数据分享平台
- Papers With Code数据集, https://paperswithcode.com/datasets, 机器学习数据集
- Kaggle, https://www.kaggle.com/datasets, 包含各种有趣的数据集，如拉面评级、篮球数据等
- Hugging Face, https://huggingface.co/datasets,  AI社区，提供各种数据集
- CLUE 数据集, https://www.cluebenchmarks.com/dataSet_search.html, 中文数据集搜索引擎
- UCI 机器学习库, https://archive-beta.ics.uci.edu/
- Datasets for Data Science, Machine Learning, AI & Analytics, https://www.kdnuggets.com/datasets/index.html
- DataCastle数据科学学习社区, https://www.datacastle.cn/dataset_list.html


## 4. 微调框架


### Kiln

> [Kiln](https://github.com/Kiln-AI), Zero-code fine-tuning for Llama, GPT4o, and Mixtral. Automatic serverless deployment of models.
> 参考：https://docs.getkiln.ai/docs/fine-tuning-guide

全托管，零代码，定义模型能力，生成合成数据、选择模型在线训练、在线使用训练好的模型。


### Unsloth

> [Unsloth](https://github.com/unslothai/unsloth), finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory.
>- https://unsloth.ai/blog/deepseek-r1

更快、更省内存，仅支持NVIDIA GPU。





## 5. 参考文章

- https://github.com/AndersonBY/deepseek-tokenizer, 