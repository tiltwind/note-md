<!---
markmeta_author: titlwind
markmeta_date: 2025-02-19
markmeta_title: 模型微调(fine-tuning)
markmeta_categories: ai
markmeta_tags: ai,fine-tuning
-->


# 微调

## 1. 什么是微调


### 1.1. 预训练 vs 微调

- **大模型训练（Pre-training）**  
  - **目标**：通过海量通用数据（如网页、书籍）学习语言的底层模式和知识（语法、逻辑、常识）。  
  - **方法**：无监督或自监督学习（如预测被遮挡的词、生成下一句话）。  
  - **特点**：需要巨量计算资源（数千张GPU/TPU）、长时间训练（数周至数月）。  
  - **输出**：通用基础模型（如GPT-3、BERT）。

- **微调（Fine-tuning）**  
  - **目标**：在预训练模型基础上，用特定领域数据（如医学文献、法律合同）适配具体任务（分类、问答）。  
  - **方法**：监督学习（使用标注数据调整模型参数）。  
  - **特点**：资源消耗低（单卡或少量GPU）、训练时间短（几小时至几天）。  
  - **输出**：领域专用模型（如医疗问答机器人）。

| **维度**| **大模型训练**     | **微调** |
|----------------|----------------------------|-----------------------------|
| **数据**| 通用数据（TB级） | 领域数据（GB级） |
| **任务**| 学习语言基础能力 | 适配具体任务（如分类、生成） |
| **参数更新**   | 所有参数从头训练 | 部分或全部参数小幅调整     |
| **资源需求**   | 千亿级算力（如超算集群）   | 百亿级算力（如单台服务器） |
| **典型模型**   | GPT-4、LLAMA、PaLM| ChatGPT（基于GPT-3微调）   |


## 2. 什么时候需要微调

### 2.2. 微调的好处

- **微调可以做 RAG 能做的所有事情，但 RAG 不能**：  Fine-tuning 可以通过在训练期间将外部知识直接嵌入到模型中来复制 RAG 的功能，使其能够在不依赖外部系统的情况下执行诸如回答小众问题或总结文档等任务。微调还可以将上下文和模式集成到模型中，模拟检索行为。
- **特定任务更强的掌控能力**：微调将有关领域或任务知识直接嵌入到模型中，使其能够高精度地处理结构化、重复或细微差别的查询，这是 RAG 无法单独实现的。
- **独立于检索**： 微调模型无需外部数据即可有效运行，即使在检索系统出现故障或知识库不完整时也能确保无缝性能。
- **更快的推理**： 微调模型无需检索步骤即可提供直接响应，使其成为速度至关重要的场景的理想选择。
- **自定义行为和语气**： 微调允许精确控制模型的行为和通信方式，确保与品牌声音、法规要求或其他约束保持一致。
- **系统降级稳健性**： 在组合系统中，微调模型可确保可靠任务性能的基线水平，即使 RAG 系统检索不相关或不完整的信息也是如此。


### 2.3. 为什么你应该结合RAG和微调呢？

- **任务处理更专业**：微调擅长于特定任务，而 RAG 则动态检索最新或外部知识。它们共同处理核心和特定于上下文的需求。
- **适应性**：RAG 使系统无需不断重新训练即可保持最新状态。
- **效率**：微调建立了基线，而 RAG 通过处理动态细节减少了对详尽训练的需求。



## 3. 微调相关概念


### 3.1. LoRA

LoRA模型，全称Low-Rank Adaptation of Large Language Models，是一种用于微调大型语言模型的低秩适应技术。它最初应用于NLP领域，特别是用于微调GPT-3等模型。LoRA通过仅训练低秩矩阵，然后将这些参数注入到原始模型中，从而实现对模型的微调。这种方法不仅减少了计算需求，而且使得训练资源比直接训练原始模型要小得多，因此非常适合在资源有限的环境中使用。

在Stable Diffusion（SD）模型的应用中，LoRA被用作一种插件，允许用户在不修改SD模型的情况下，利用少量数据训练出具有特定画风、IP或人物特征的模型。这种技术在社区使用和个人开发者中非常受欢迎。例如，可以通过LoRA模型改变SD模型的生成风格，或者为SD模型添加新的人物/IP。

LoRA模型的使用涉及安装插件和配置参数。用户需要下载适合的LoRA模型和相应的checkpoint模型，并将其安装到相应的目录。在使用时，可以将LoRA模型与大模型结合使用，通过调整LoRA的权重来控制生成图片的结果。LoRA模型的优点包括训练速度快、计算需求低、训练权重小，因为原始模型被冻结，我们注入新的可训练层，可以将新层的权重保存为一个约3MB大小的文件，比UNet模型的原始大小小了近一千倍。

总的来说，LoRA模型是一种高效、灵活且适用于多种场景的模型微调技术，它在保持原始模型性能的同时，允许用户根据需要进行定制化调整。

> 参考: LoRA: Low-Rank Adaptation of Large Language Models, https://arxiv.org/abs/2106.09685

### 3.2. QLoRA

QLoRA是一种针对大语言模型的高效微调方法，能在有限的显存条件下，如48GB GPU上微调65B参数模型，同时保持与16位精度相当的性能。

通过**4位浮点数量化、双量化和分页优化器**，QLoRA解决了显存瓶颈问题，实现了在消费级硬件上微调大型模型。但会存在精度丢失问题, Unsloth 的动态 4 位量化在很大程度上减少了精度丢失问题。

此外，QLoRA微调的模型在聊天机器人任务中展现出与ChatGPT相当的性能，降低了计算资源的门槛。

> 参考: QLoRA: Efficient Finetuning of Quantized LLMs, https://arxiv.org/abs/2305.14314



## 4. 模型的选择


| 模型类型 | 定义     | 应用场景 | 特点     | 范例  | 是否适合微调 |
|---------|---------|---------|---------|-------|------------|
| 基座模型 | 大规模预训练模型，具备广泛任务适应性，作为下游任务起点     | 通用文本生成、代码生成、问答 | 参数规模大（数亿至万亿级），依赖无监督预训练，需微调适配具体场景     | GPT-4、Llama 2、Gemma     | 是 |
| 多模态模型| 支持文本、图像、语音等多模态输入输出的统一模型   | 跨模态生成、视觉推理、语音交互 | 端到端多模态融合架构，训练数据多样，硬件要求高   | Step-1o系列、GPT-4V| 是（需多模态数据） |
| 垂类大模型| 针对特定行业（如医疗、金融）深度优化的模型| 法律合同分析、医学影像识别   | 融合领域知识库，牺牲通用性换取垂直场景精度| 法律版GPT、医疗专用LLM    | 是（需行业数据） |
| 轻量化模型| 通过剪枝、蒸馏等技术压缩的轻量级模型   | 移动端部署、实时推理| 参数规模小（如2B-7B），推理速度快，牺牲部分精度  | CodeGemma 2B、TinyLlama   | 有限微调      |
| 专用模型 | 为单一任务设计的模型（如分类、翻译）   | 文本分类、机器翻译 | 架构针对任务优化（如编码器或解码器为主），泛化能力弱| BERT、T5 | 通常不适用    |
| 领域自适应模型     | 在基座模型基础上注入特定领域数据进行二次训练的模型| 生物医药文献解析、金融报告生成 | 保留基座通用能力，增强领域术语理解     | 科学文献版Llama | 是 |
| 代理模型 | 具备环境交互、规划与决策能力的智能体模型| 游戏NPC、自主机器人| 集成强化学习框架，支持多模态感知-行动闭环| 微软交互式AI基础模型      | 是（需交互数据） |
| 生成式对抗模型     | 基于生成器与判别器对抗训练的生成模型   | 图像生成、数据增强 | 擅长生成逼真数据，训练稳定性差，需精细调参| StyleGAN、Stable Diffusion| 有限微调      |
| 检索增强模型| 结合外部知识库实时检索的生成模型| 事实性问答、个性化推荐| 降低幻觉风险，依赖检索系统性能| RAG架构模型     | 是（需调整检索策略） |
| 边缘优化模型| 针对边缘设备（如手机、IoT）设计的低功耗模型      | 实时语音助手、设备端AI| 量化压缩技术应用，支持低精度计算| MobileBERT、TensorFlow Lite模型 | 通常预固化   |

  
**对比说明**：  
1. **基座模型**作为基础设施，需结合RAG、微调等技术落地；**多模态模型**成为2025年竞争焦点（如阶跃星辰Step-1o系列）。  
2. **垂类大模型**与**领域自适应模型**的区别在于：前者从预训练阶段融入领域数据，后者主要在微调阶段注入知识。  
3. **代理模型**强调动态交互能力，常需与仿真环境联合训练；**轻量化模型**通过结构改进（如MoE）平衡性能与效率。  
4. 是否适合微调与模型开放程度相关，例如商用闭源模型（如GPT-4）仅支持Prompt工程，开源模型（如Llama）支持全参数微调。



## 5. 微调数据格式

参考： https://www.xfyun.cn/doc/spark/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E.html



## 6. 开放数据集

- Registry of Open Data on AWS, https://registry.opendata.aws/
- AI Studio数据集, https://aistudio.baidu.com/aistudio/datasetoverview, 百度AI Studio的人工智能学习与实训社区，提供开放数据集。
- 天池数据集, https://tianchi.aliyun.com, 阿里对外开放数据分享平台
- Papers With Code数据集, https://paperswithcode.com/datasets, 机器学习数据集
- Kaggle, https://www.kaggle.com/datasets, 包含各种有趣的数据集，如拉面评级、篮球数据等
- Hugging Face, https://huggingface.co/datasets,  AI社区，提供各种数据集
- CLUE 数据集, https://www.cluebenchmarks.com/dataSet_search.html, 中文数据集搜索引擎
- UCI 机器学习库, https://archive-beta.ics.uci.edu/
- Datasets for Data Science, Machine Learning, AI & Analytics, https://www.kdnuggets.com/datasets/index.html
- DataCastle数据科学学习社区, https://www.datacastle.cn/dataset_list.html


## 4. 微调框架


### Kiln

> [Kiln](https://github.com/Kiln-AI), Zero-code fine-tuning for Llama, GPT4o, and Mixtral. Automatic serverless deployment of models.
> 参考：https://docs.getkiln.ai/docs/fine-tuning-guide

全托管，零代码，定义模型能力，生成合成数据、选择模型在线训练、在线使用训练好的模型。


### Unsloth

> [Unsloth](https://github.com/unslothai/unsloth), finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory.
>   - https://unsloth.ai/blog/deepseek-r1

更快、更省内存，仅支持NVIDIA GPU。





## 5. 参考文章

- https://github.com/AndersonBY/deepseek-tokenizer, 