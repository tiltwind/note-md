<!---
markmeta_author: titlwind
markmeta_date: 2025-02-19
markmeta_title: LLM 词汇
markmeta_categories: ai
markmeta_tags: ai,llm,terms
-->


# LLM 词汇


## 机器学习（Machine Learning）
机器学习是人工智能（AI）的一个核心分支，它使计算机系统能够从数据中学习并做出决策，而无需进行显式编程。该领域专注于开发能够自主识别模式、从经验中学习并持续提升性能的算法。机器学习主要分为三种类型：监督学习、非监督学习和强化学习。在监督学习中，模型通过带标签的数据进行训练，以预测未来的输出。非监督学习则处理未标记的数据，旨在发现数据中隐藏的结构和模式。强化学习通过与环境的互动来学习，通过奖励和惩罚机制来优化其行为策略。机器学习的应用无处不在，例如在垃圾邮件过滤、个性化推荐系统、医疗诊断和自动驾驶等领域都发挥着关键作用。

## 监督学习（Supervised Learning）
监督学习是机器学习中最常用的一种方法，其核心思想是利用一组带有明确标签的训练数据来训练模型。在监督学习中，每个数据样本都包含一个输入特征和一个对应的正确输出（标签）。模型的目标是学习输入与输出之间的映射关系，以便在接收到新的、未见过的数据时能够准确预测其输出。监督学习主要分为两类任务：分类和回归。分类任务旨在预测离散的类别标签，如判断一封邮件是否为垃圾邮件；回归任务则用于预测连续的数值，如预测房价或股票价格。常见的监督学习算法包括线性回归、逻辑回归、支持向量机（SVM）、决策树和神经网络等。

## 非监督学习（Unsupervised Learning）
非监督学习是机器学习的另一个重要分支，它主要处理没有标签的数据。与监督学习不同，非监督学习算法需要在没有明确指导的情况下，自主地发现数据中的内在结构、模式和关系。其核心目标是对数据进行探索性分析，从而揭示其潜在的组织形式。非监督学习最常见的任务是聚类和降维。聚类是将数据分成不同的组（或簇），使得同一组内的数据点具有较高的相似性，而不同组之间的数据点则差异较大，常用于客户细分和市场分析。降维旨在减少数据集中的特征数量，同时保留最重要的信息，以便于数据可视化和后续处理。主成分分析（PCA）是降维的代表性算法。

## SFT（监督式微调）
SFT（Supervised Fine-Tuning）即有监督微调，是大型语言模型（LLM）训练过程中的一个关键步骤。在预训练（Pre-training）阶段，模型通过海量的无标签文本数据学习通用的语言知识。然而，为了让模型能够更好地理解和遵循人类的指令，或者在特定领域（如医疗、法律）表现更出色，就需要进行SFT。SFT使用一个规模相对较小、经过人工标注的高质量数据集，其中包含了“指令-回答”对。通过在这个数据集上进行有监督的训练，模型能够学习如何根据具体的指令生成更准确、更相关、更符合人类期望的回答。这个过程极大地提升了模型在特定任务上的性能和“对齐”能力，使其从一个通用的语言模型转变为一个专业的任务助手。

## 预训练（Pre-training）
通过海量通用数据（如网页、书籍）学习语言的底层模式和知识（语法、逻辑、常识）。 
无监督或自监督学习（如预测被遮挡的词、生成下一句话）。  
需要巨量计算资源（数千张GPU/TPU）、长时间训练（数周至数月）。  
通用基础模型（如GPT-3、BERT）。

## 微调（Fine-tuning）
在预训练模型基础上，用特定领域数据（如医学文献、法律合同）适配具体任务（分类、问答）。  
监督学习（使用标注数据调整模型参数）。  
资源消耗低（单卡或少量GPU）、训练时间短（几小时至几天）。  
领域专用模型（如医疗问答机器人）。